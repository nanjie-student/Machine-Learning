{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:34:32.570380Z",
     "start_time": "2020-06-02T02:34:26.924684Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from urllib.request import urlopen \n",
    "%matplotlib inline\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,precision_score, recall_score, auc,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:34:37.852493Z",
     "start_time": "2020-06-02T02:34:37.844918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data and cleaning dataset\n",
    "UCI_data_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases\\\n",
    "/breast-cancer-wisconsin/wdbc.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created a list with the appropriate names and set them as the data frame's column names,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:34:49.286914Z",
     "start_time": "2020-06-02T02:34:49.278018Z"
    }
   },
   "outputs": [],
   "source": [
    "names = ['id_number', 'diagnosis', 'radius_mean', \n",
    "         'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "         'smoothness_mean', 'compactness_mean', \n",
    "         'concavity_mean','concave_points_mean', \n",
    "         'symmetry_mean', 'fractal_dimension_mean',\n",
    "         'radius_se', 'texture_se', 'perimeter_se', \n",
    "         'area_se', 'smoothness_se', 'compactness_se', \n",
    "         'concavity_se', 'concave_points_se', \n",
    "         'symmetry_se', 'fractal_dimension_se', \n",
    "         'radius_worst', 'texture_worst', \n",
    "         'perimeter_worst', 'area_worst', \n",
    "         'smoothness_worst', 'compactness_worst', \n",
    "         'concavity_worst', 'concave_points_worst', \n",
    "         'symmetry_worst', 'fractal_dimension_worst'] \n",
    "\n",
    "dx = ['Benign', 'Malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:34:57.774849Z",
     "start_time": "2020-06-02T02:34:57.083380Z"
    }
   },
   "outputs": [],
   "source": [
    "wbcd_df = pd.read_csv(urlopen(UCI_data_URL), names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave_points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_number diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
       "0         0.2419                 0.07871     1.0950      0.9053         8.589   \n",
       "1         0.1812                 0.05667     0.5435      0.7339         3.398   \n",
       "2         0.2069                 0.05999     0.7456      0.7869         4.585   \n",
       "3         0.2597                 0.09744     0.4956      1.1560         3.445   \n",
       "4         0.1809                 0.05883     0.7572      0.7813         5.438   \n",
       "\n",
       "   area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  \\\n",
       "0   153.40       0.006399         0.04904       0.05373            0.01587   \n",
       "1    74.08       0.005225         0.01308       0.01860            0.01340   \n",
       "2    94.03       0.006150         0.04006       0.03832            0.02058   \n",
       "3    27.23       0.009110         0.07458       0.05661            0.01867   \n",
       "4    94.44       0.011490         0.02461       0.05688            0.01885   \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
       "0      0.03003              0.006193         25.38          17.33   \n",
       "1      0.01389              0.003532         24.99          23.41   \n",
       "2      0.02250              0.004571         23.57          25.53   \n",
       "3      0.05963              0.009208         14.91          26.50   \n",
       "4      0.01756              0.005115         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave_points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "We do some minor cleanage like setting the id_number to be the data frame index, along with converting the diagnosis to the standard binary 1, 0 representation using the map() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:03.295302Z",
     "start_time": "2020-06-02T02:35:03.270091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting 'id_number' as our index\n",
    "wbcd_df.set_index(['id_number'], inplace = True) \n",
    "# Converted to binary to help later on with models and plots\n",
    "wbcd_df['diagnosis'] = wbcd_df['diagnosis'].map({'M':1, 'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave_points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id_number                                                                    \n",
       "842302             1        17.99         10.38          122.80     1001.0   \n",
       "842517             1        20.57         17.77          132.90     1326.0   \n",
       "84300903           1        19.69         21.25          130.00     1203.0   \n",
       "84348301           1        11.42         20.38           77.58      386.1   \n",
       "84358402           1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "           smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id_number                                                      \n",
       "842302             0.11840           0.27760          0.3001   \n",
       "842517             0.08474           0.07864          0.0869   \n",
       "84300903           0.10960           0.15990          0.1974   \n",
       "84348301           0.14250           0.28390          0.2414   \n",
       "84358402           0.10030           0.13280          0.1980   \n",
       "\n",
       "           concave_points_mean  symmetry_mean  fractal_dimension_mean  \\\n",
       "id_number                                                               \n",
       "842302                 0.14710         0.2419                 0.07871   \n",
       "842517                 0.07017         0.1812                 0.05667   \n",
       "84300903               0.12790         0.2069                 0.05999   \n",
       "84348301               0.10520         0.2597                 0.09744   \n",
       "84358402               0.10430         0.1809                 0.05883   \n",
       "\n",
       "           radius_se  texture_se  perimeter_se  area_se  smoothness_se  \\\n",
       "id_number                                                                \n",
       "842302        1.0950      0.9053         8.589   153.40       0.006399   \n",
       "842517        0.5435      0.7339         3.398    74.08       0.005225   \n",
       "84300903      0.7456      0.7869         4.585    94.03       0.006150   \n",
       "84348301      0.4956      1.1560         3.445    27.23       0.009110   \n",
       "84358402      0.7572      0.7813         5.438    94.44       0.011490   \n",
       "\n",
       "           compactness_se  concavity_se  concave_points_se  symmetry_se  \\\n",
       "id_number                                                                 \n",
       "842302            0.04904       0.05373            0.01587      0.03003   \n",
       "842517            0.01308       0.01860            0.01340      0.01389   \n",
       "84300903          0.04006       0.03832            0.02058      0.02250   \n",
       "84348301          0.07458       0.05661            0.01867      0.05963   \n",
       "84358402          0.02461       0.05688            0.01885      0.01756   \n",
       "\n",
       "           fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  \\\n",
       "id_number                                                                       \n",
       "842302                 0.006193         25.38          17.33           184.60   \n",
       "842517                 0.003532         24.99          23.41           158.80   \n",
       "84300903               0.004571         23.57          25.53           152.50   \n",
       "84348301               0.009208         14.91          26.50            98.87   \n",
       "84358402               0.005115         22.54          16.67           152.20   \n",
       "\n",
       "           area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "id_number                                                                     \n",
       "842302         2019.0            0.1622             0.6656           0.7119   \n",
       "842517         1956.0            0.1238             0.1866           0.2416   \n",
       "84300903       1709.0            0.1444             0.4245           0.4504   \n",
       "84348301        567.7            0.2098             0.8663           0.6869   \n",
       "84358402       1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "           concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "id_number                                                                 \n",
       "842302                   0.2654          0.4601                  0.11890  \n",
       "842517                   0.1860          0.2750                  0.08902  \n",
       "84300903                 0.2430          0.3613                  0.08758  \n",
       "84348301                 0.2575          0.6638                  0.17300  \n",
       "84358402                 0.1625          0.2364                  0.07678  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Given context of the data set, we know that there is no missing data, but we want to make sure that there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:07.555212Z",
     "start_time": "2020-06-02T02:35:07.530091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave_points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave_points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave_points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "\n",
    "Let us explore the data to get some insight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:16.052660Z",
     "start_time": "2020-06-02T02:35:15.958521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave_points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id_number                                                                    \n",
       "842302             1        17.99         10.38          122.80     1001.0   \n",
       "842517             1        20.57         17.77          132.90     1326.0   \n",
       "84300903           1        19.69         21.25          130.00     1203.0   \n",
       "84348301           1        11.42         20.38           77.58      386.1   \n",
       "84358402           1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "           smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id_number                                                      \n",
       "842302             0.11840           0.27760          0.3001   \n",
       "842517             0.08474           0.07864          0.0869   \n",
       "84300903           0.10960           0.15990          0.1974   \n",
       "84348301           0.14250           0.28390          0.2414   \n",
       "84358402           0.10030           0.13280          0.1980   \n",
       "\n",
       "           concave_points_mean  symmetry_mean  fractal_dimension_mean  \\\n",
       "id_number                                                               \n",
       "842302                 0.14710         0.2419                 0.07871   \n",
       "842517                 0.07017         0.1812                 0.05667   \n",
       "84300903               0.12790         0.2069                 0.05999   \n",
       "84348301               0.10520         0.2597                 0.09744   \n",
       "84358402               0.10430         0.1809                 0.05883   \n",
       "\n",
       "           radius_se  texture_se  perimeter_se  area_se  smoothness_se  \\\n",
       "id_number                                                                \n",
       "842302        1.0950      0.9053         8.589   153.40       0.006399   \n",
       "842517        0.5435      0.7339         3.398    74.08       0.005225   \n",
       "84300903      0.7456      0.7869         4.585    94.03       0.006150   \n",
       "84348301      0.4956      1.1560         3.445    27.23       0.009110   \n",
       "84358402      0.7572      0.7813         5.438    94.44       0.011490   \n",
       "\n",
       "           compactness_se  concavity_se  concave_points_se  symmetry_se  \\\n",
       "id_number                                                                 \n",
       "842302            0.04904       0.05373            0.01587      0.03003   \n",
       "842517            0.01308       0.01860            0.01340      0.01389   \n",
       "84300903          0.04006       0.03832            0.02058      0.02250   \n",
       "84348301          0.07458       0.05661            0.01867      0.05963   \n",
       "84358402          0.02461       0.05688            0.01885      0.01756   \n",
       "\n",
       "           fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  \\\n",
       "id_number                                                                       \n",
       "842302                 0.006193         25.38          17.33           184.60   \n",
       "842517                 0.003532         24.99          23.41           158.80   \n",
       "84300903               0.004571         23.57          25.53           152.50   \n",
       "84348301               0.009208         14.91          26.50            98.87   \n",
       "84358402               0.005115         22.54          16.67           152.20   \n",
       "\n",
       "           area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "id_number                                                                     \n",
       "842302         2019.0            0.1622             0.6656           0.7119   \n",
       "842517         1956.0            0.1238             0.1866           0.2416   \n",
       "84300903       1709.0            0.1444             0.4245           0.4504   \n",
       "84348301        567.7            0.2098             0.8663           0.6869   \n",
       "84358402       1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "           concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "id_number                                                                 \n",
       "842302                   0.2654          0.4601                  0.11890  \n",
       "842517                   0.1860          0.2750                  0.08902  \n",
       "84300903                 0.2430          0.3613                  0.08758  \n",
       "84348301                 0.2575          0.6638                  0.17300  \n",
       "84358402                 0.1625          0.2364                  0.07678  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:22.982024Z",
     "start_time": "2020-06-02T02:35:22.975143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the dimensions of our data:\n",
      " (569, 31)\n"
     ]
    }
   ],
   "source": [
    "# dimension of the data\n",
    "print(\"Here's the dimensions of our data:\\n\", wbcd_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:29.414862Z",
     "start_time": "2020-06-02T02:35:29.398322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the data types of various variables:\n",
      " diagnosis                    int64\n",
      "radius_mean                float64\n",
      "texture_mean               float64\n",
      "perimeter_mean             float64\n",
      "area_mean                  float64\n",
      "smoothness_mean            float64\n",
      "compactness_mean           float64\n",
      "concavity_mean             float64\n",
      "concave_points_mean        float64\n",
      "symmetry_mean              float64\n",
      "fractal_dimension_mean     float64\n",
      "radius_se                  float64\n",
      "texture_se                 float64\n",
      "perimeter_se               float64\n",
      "area_se                    float64\n",
      "smoothness_se              float64\n",
      "compactness_se             float64\n",
      "concavity_se               float64\n",
      "concave_points_se          float64\n",
      "symmetry_se                float64\n",
      "fractal_dimension_se       float64\n",
      "radius_worst               float64\n",
      "texture_worst              float64\n",
      "perimeter_worst            float64\n",
      "area_worst                 float64\n",
      "smoothness_worst           float64\n",
      "compactness_worst          float64\n",
      "concavity_worst            float64\n",
      "concave_points_worst       float64\n",
      "symmetry_worst             float64\n",
      "fractal_dimension_worst    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Type of variables\n",
    "\n",
    "print(\"Here's the data types of various variables:\\n\", wbcd_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will see some useful standard descriptive statistics for each feature \n",
    "including mean, standard deviation, minimum value, maximum value, and range intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:45.448431Z",
     "start_time": "2020-06-01T23:05:45.230237Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave_points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean   radius_se  texture_se  \\\n",
       "count     569.000000              569.000000  569.000000  569.000000   \n",
       "mean        0.181162                0.062798    0.405172    1.216853   \n",
       "std         0.027414                0.007060    0.277313    0.551648   \n",
       "min         0.106000                0.049960    0.111500    0.360200   \n",
       "25%         0.161900                0.057700    0.232400    0.833900   \n",
       "50%         0.179200                0.061540    0.324200    1.108000   \n",
       "75%         0.195700                0.066120    0.478900    1.474000   \n",
       "max         0.304000                0.097440    2.873000    4.885000   \n",
       "\n",
       "       perimeter_se     area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "count    569.000000  569.000000     569.000000      569.000000    569.000000   \n",
       "mean       2.866059   40.337079       0.007041        0.025478      0.031894   \n",
       "std        2.021855   45.491006       0.003003        0.017908      0.030186   \n",
       "min        0.757000    6.802000       0.001713        0.002252      0.000000   \n",
       "25%        1.606000   17.850000       0.005169        0.013080      0.015090   \n",
       "50%        2.287000   24.530000       0.006380        0.020450      0.025890   \n",
       "75%        3.357000   45.190000       0.008146        0.032450      0.042050   \n",
       "max       21.980000  542.200000       0.031130        0.135400      0.396000   \n",
       "\n",
       "       concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "count         569.000000   569.000000            569.000000    569.000000   \n",
       "mean            0.011796     0.020542              0.003795     16.269190   \n",
       "std             0.006170     0.008266              0.002646      4.833242   \n",
       "min             0.000000     0.007882              0.000895      7.930000   \n",
       "25%             0.007638     0.015160              0.002248     13.010000   \n",
       "50%             0.010930     0.018730              0.003187     14.970000   \n",
       "75%             0.014710     0.023480              0.004558     18.790000   \n",
       "max             0.052790     0.078950              0.029840     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some summary of the data\n",
    "wbcd_df.describe()\n",
    "#wbcd_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see through the maximum row that our data varies in distribution, this will be important when considering classification models.\n",
    "\n",
    "Standardization is an important requirement for many classification models that should be considered when implementing pre-processing. Some models can perform poorly if pre-processing isn't considered, so the describe() function can be a good indicator for standardization. Fortunately Random Forest does not require any pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "The distribution for diagnosis is important because it brings up the discussion of Class Imbalance within Machine learning and data mining applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:38.704974Z",
     "start_time": "2020-06-02T02:35:38.680309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:42.936087Z",
     "start_time": "2020-06-02T02:35:42.797090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: diagnosis, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the perecentage of each class\n",
    "\n",
    "wbcd_df['diagnosis'].value_counts()/len(wbcd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, this data set does not suffer from class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Test Sets\n",
    "\n",
    "We split the data set into our training and test sets which will be randomly selected having a 80-20% splt. We will use the training set to train our model, and use our test set as the unseen data that will be a useful final metric to let us know how well our model does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:45.544569Z",
     "start_time": "2020-06-01T23:05:45.529495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave_points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbcd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:35:51.729513Z",
     "start_time": "2020-06-02T02:35:51.721423Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = wbcd_df.iloc[:, wbcd_df.columns != 'diagnosis']\n",
    "#y = wbcd_df.iloc[:, wbcd_df.columns == 'diagnosis']\n",
    "X = wbcd_df.iloc[:, 1:]\n",
    "y = wbcd_df.iloc[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:37:06.600577Z",
     "start_time": "2020-06-02T02:37:06.591253Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare models\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:37:08.428802Z",
     "start_time": "2020-06-02T02:37:08.423890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare configuration for cross validation test \n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T02:37:12.653874Z",
     "start_time": "2020-06-02T02:37:10.562212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.942043 (0.038440)\n",
      "RF: 0.959618 (0.029385)\n",
      "KNN: 0.926253 (0.046232)\n",
      "DT: 0.927914 (0.028864)\n",
      "NB: 0.936779 (0.036077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.915758 (0.077166)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model \n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:47.448111Z",
     "start_time": "2020-06-01T23:05:47.036102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:47.461080Z",
     "start_time": "2020-06-01T23:05:47.452720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate each model \n",
    "# evaluate each model in turn\n",
    "Models = [\n",
    "    #Ensemble Methods\n",
    "    sklearn.ensemble.RandomForestClassifier(),\n",
    "\n",
    "    \n",
    "    #GLM\n",
    "    sklearn.linear_model.LogisticRegressionCV(),\n",
    "\n",
    "    #Navies Bayes\n",
    "    sklearn.naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    sklearn.neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    sklearn.svm.SVC(probability=True),\n",
    "    \n",
    "    #Trees    \n",
    "    sklearn.tree.DecisionTreeClassifier()\n",
    "    \n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:47.475923Z",
     "start_time": "2020-06-01T23:05:47.463769Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:49.275038Z",
     "start_time": "2020-06-01T23:05:47.478775Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "Model_columns = []\n",
    "Model_compare = pd.DataFrame(columns = Model_columns)\n",
    "\n",
    "row_index = 0\n",
    "for model in Models:\n",
    "    \n",
    "    \n",
    "    predicted = model.fit(x_train, y_train).predict(x_test)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    Model_name = model.__class__.__name__\n",
    "    Model_compare.loc[row_index,'Model Name'] = Model_name\n",
    "    Model_compare.loc[row_index, 'Model Train Accuracy'] = round(model.score(x_train, y_train), 4)\n",
    "    Model_compare.loc[row_index, 'Model Test Accuracy'] = round(model.score(x_test, y_test), 4)\n",
    "    Model_compare.loc[row_index, 'Model Precision'] = precision_score(y_test, predicted)\n",
    "    Model_compare.loc[row_index, 'Model Recall'] = recall_score(y_test, predicted)\n",
    "    Model_compare.loc[row_index, 'Model AUC'] = auc(fp, tp)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "Model_compare.sort_values(by = ['Model Test Accuracy'], ascending = False, inplace = True)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Train Accuracy</th>\n",
       "      <th>Model Test Accuracy</th>\n",
       "      <th>Model Precision</th>\n",
       "      <th>Model Recall</th>\n",
       "      <th>Model AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.952273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.943182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.928409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  Model Train Accuracy  Model Test Accuracy  \\\n",
       "1    LogisticRegressionCV                0.9765               0.9580   \n",
       "0  RandomForestClassifier                1.0000               0.9510   \n",
       "2              GaussianNB                0.9413               0.9441   \n",
       "3    KNeighborsClassifier                0.9390               0.9371   \n",
       "5  DecisionTreeClassifier                1.0000               0.9371   \n",
       "4                     SVC                0.9249               0.9091   \n",
       "\n",
       "   Model Precision  Model Recall  Model AUC  \n",
       "1         0.962264      0.927273   0.952273  \n",
       "0         0.961538      0.909091   0.943182  \n",
       "2         0.943396      0.909091   0.937500  \n",
       "3         0.925926      0.909091   0.931818  \n",
       "5         0.942308      0.890909   0.928409  \n",
       "4         0.956522      0.800000   0.888636  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  Model_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T23:05:49.609475Z",
     "start_time": "2020-06-01T23:05:49.278423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAH0CAYAAABinf+DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xm4JFV9//H3YRhERXEZt2GRRVwGVAQ0LhHcBVQgxHwFRWVRonEJ4hKI/kRxI6IYVKIiyqJR/IKagCKoKKJGIi4ssigjggxIEEFZhRmo3x9VF5rmzty+M91dfYv363n6uV2nqrs+3bfmTn/7nDpVqqpCkiRJktRdq7UdQJIkSZI0WhZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpI0x5VSdi+lLJvlY95TSlk8qkwD7H/bUkpVSlnQVgbNbaWUM0opn2w7hyTNFRZ+kjQipZSjmuLmq9Os26lZN6uCbRxKKRs02VZ0O20Vd/M94BHAn1Y9MZTab0opy0opjxnGc3ZBKeWZpZT/LqVcVUr5ayllcSnl6FLKE9vONgTbA/u3HUKS5goLP0kard8DLymlPKyvfW/g0hbyDOIy6qJs6vbGpr23befpHlhKWWOQHVRVdWtVVVdWVVWtelwAng3cG/gi8NohPecqGfS9GOH+XwecBlwP7Ao8Fng58AfgkPaSrZqp97Wqqmuqqrq+7TySNFdY+EnSaF0EnAHsPtVQSlkfeD5wZP/GpZTtSyk/L6Xc0vTS/Ecp5b4960sp5X3NuhtKKccCD5zmeZ5fSvlxKeXmUsrlpZQjSykPHiRwVVW3NUXZlVVVXQn8pWm/sud2TSllzab37/WllCylXA98vtn/waWUC0spN5VSfl9K+UQpZa2efHcZ6tmz/Oye3OeWUp49SGbgH4EvNPt/9XRFVyllt1LKWU3P19WllG9MZWre132azLeUUv6vlPKlnsdeWUp5W9/zfbGUcnLP8hmllE+VUg4qpVwJ/LZpf3Up5cxSynWllD+WUk4opWzc91yPKKUc09Mzd2GTd14pZUkpZd++7ddu3ttdpnszSikbAB8HPlFV1W5VVZ1aVdUlVVX9tKqq/YCX9my7aSnl5FLKjaWU60sp/9U8fmr965pj7fmllPOa382ppZSHlVKeW0o5p1l/Sinl4T2PO6iU8qtSD0W+pHldJzfH/9Q2mzT7u7J5PWeXUl7W91qW977eZahnc+z8pMlyXSnll73Hzyxe57OaHDeVUv63dKN3VJIs/CRpDA4HXlNKKc3ya4BT6evxK6U8ATgBOB3YHHg18GLg0z2bvRnYF3g7sAXwC+CAvud5DvDfwLHAE4CdgA2Ar/dkGKYDqYdubg68p2m7HtgLWET9ercDPjrAc32keY4nAucBx/UWjNMppTyU+jUeXVXV6dSF6s5927yeuig8FngS8Jwm87xmk4Oa1/HvwGbAi4BzB8jbbzfgPtQ9kNs3bWtQ/46eBGwLzAdOKKWs3mRbC/ghdY/cLtTv2VuAW6qqug34HPV72L+fm4CvLyfHLs1+3j/dyqqqru3Z93eACvhb6vdlAXDSVL7GvaiHVe4ObA1sBHwFeGeTbRvgUcC/9e1qA2AP6t/HNsBDgeN71t8POJn6i5DHA0cDXyqlPH2a19v/vt6hlHIv6n87P6A+DrdqXvtfV+J1vgd4ffMcNwHHllL8vCRp7quqyps3b968jeAGHAV8F1iT+ly2Z1MXGkuoPwjvDizr2f4LwE/7nmNH4Hbgkc3yEuADfdsc3/c8pwEH9W2zPvWH3s2b5fcAiwd8HbvV/13crX3N5jkPG+A5dgWu71netnnsgr7l7Xu22aBp22aG5/4X4Cc9y+8GvtezXID/Az6ynMc/ELgVeOMK9nEl8La+ti8CJ/csnwH8Cigz5H1E87q2bJbfANwAPGw5268HLAP+tqftl8BHV7CPzwNXDfB7eQNwHfCAnrZ1m/cjmuXXNXkf27PN/2vaNu1p2x9Y0rN8EHAbsH5P2xOax/3tCjKdQt1TucL3tWn/ZN97+tQhvM5FPds8q2l75CD/Vrx58+Ztkm9+gyVJI1ZV1V+pi7rXUvckrQ6cOM2mm1L39vX6AXXhsqiUcn9gHeB/+rb5Ud/yk4F9mmFrN5RSbgDOb9ZtstIvZPl+2t9QSnlZKeVHpZQ/NPv/PLBWKeVBMzzXWT33L29+9p8f2bufQv2+Ht3TfDSwTSll6rWuR93T9O3lPM3jqXvHlrd+Ns6squou5y2WUrYs9QQrl5R6OOxFzapHNj+3BM6pqur/pnvCqqouA75Fc+5iKWUr6l6tI1aQo1AXLDPZtNn3n3v2twS4uFk35Zaqqi7sWb6Suhg9v6/toX3Pf3lVVb/vee5zqIvcRc1rWavUw4LPL6Vc2xwrz+HO92bK3d7XXlVV/YG6ED+tlPLNUso7SimPWpnXCVzQm7/5udxjUJLmCgs/SRqPz1D38r0DOLKqqqXL2W55H24r6g/zK9pmymrUQ+4277ttQl1ADNuNvQullK2BL1EPrduRekjqm5vVM014cmvP/anXuaL/q54LbAx8stQzei6jPgdsNe4+yctM79uK1t/One//lPnTbNf/XqxN/T78lXro7pOBqWGMve/FTNk+DfxDKeUB1EMrf1hV1QUr2P7XwEPLYJfLmG7f/YVj/+yzFXBbXzFWMfvPFYcC/0DdS/ss6uP0VO5+nNzIDKqqeiXwFOD71MfF+aWU3fvy9bvb65zmNYGflyR1gH/IJGkMmg/pZ1J/6F9eT8151OdB9dqG+sPn+VVV/YW6B+IZfdv0L/+Megje4mluN6zSCxnMM6mH/L23qicT+Q11r9so/CPwDe5e5L4D2L3Uk7xcBlwFvHA5z3EusHQF62kev3Bqoelp3HyAfJtRDyXdr6qqHzS9Zv3F2M+BJ5a7z/za61vAH6lng90V+OwM+/0KdbH2rulWllKmJgQ6r9n3A3rWrQts2KxbVeuUUu743ZdSHg+sxZ29altTn5t5fFVVZwOXsAq90lVVnVNV1Ueqqnoh9ZcPU8X/qF+nJE08Cz9JGp8XUp/T9tvlrD8Y2KKUckgp5bGllG2BTwD/2TNc7qPAP5dSXtnMiPhW4Hl9z/NuYMdSysdKKZuXUjYu9ayZnyul3HsUL6zPr6k/8L+ylLJRKWVP7j45ySprCqUdgWOqqvpV7426MFob2KnpwXkf8OZSyn7Ne7tZKeWfSylrV/VEJx8HPlhK+cfmfd28lPIvPbv7LrBbqWexfCzwSeDhzOx31EXlm5v34gXUv+dex1AXlieWUp5TStmw1DNo3jHzZlVVt1N/YfA+6vPmjlvRTquq+h2wT7PfLzTPu0EpZatSygd6Hn809dDLL5dSnlRKeTL1BDiLWf7EMbNxM3B0KWWLUspTqGey/VlVVT9s1v8a2LkZDrsp9ZDgQXop76KUsqiU8sFSyjNKKY8spTwDeBp3DkUd9euUpIln4SdJY1JV1U1VVV2zgvXnADtQ9/KdTX1e4DepJ52Ycih1kfIx6vPhnkY9G2Xv83yf+jypx1PPFnlOs/311EXIqH2VukA9hLo3bSfqCViGbU/qoaHf7F/RnMv1beoeMqqq+mRz/xXU78dp1AXzbc1D3kH9Pr6NugfoZOr3b8r7qYu/rzaPvYLpz9Psz3EF9RDPHaiLkA9Sz9jZu8311L2ki6kLsguof8f36nu6I6jPD/1Cc97oTPs+jPo4eACQ1EXWsdTnib6l2eYG6hk1V6M+V/R71BMRbV9VVf/wzpVxCfW5d/9Fff7qNfRcSgJ4E3XRezr1kNjfMMD7Oo3rqc8bzOY5kvq17AtjeZ2SNPHKCs6VliRJE6KUsgX1sNDHN72aE62UchDw4qqqNms7iySp/uZQkiRNqFLKmtS9dB8ATpkLRZ8kafI41FOSpMm2O/XwxYXU16OTJGnWHOopSZIkSR1nj58kSZIkdZyFnyRJkiR13Fyf3MVxqpIkSZLu6cpMG8z1wo8rrrii7QiSJEmS1IqFCxcOtJ1DPSVJkiSp4yz8JEmSJKnjLPwkSZIkqeMs/CRJkiSp4yz8JEmSJKnjLPwkSZIkqeMs/CRJkiSp4yz8JEmSJKnjLPwkSZIkqeMs/CRJkiSp41Yfx04i4vPAi4GrMnOzadYX4FBge+AmYPfM/MU4skmSJElS142rx+8oYNsVrN8O2KS57Q18agyZJEmSJOkeYSyFX2aeDlyzgk12BI7JzCozzwAeEBGPGEc2SZIkSeq6STnHbx3gsp7lJU2bJEmSJGkVjeUcvwGUadqq6TaMiL2ph4OSmSxYsGDWO3v7fl/iit9eOuvHaTIs3PiRHHzQy8e2v199eF9uvOR3Y9ufhue+G2zIZu84pO0YkiSNzQmffy+33nJV2zG0Eta410PZYc8DRvb8k1L4LQHW61leF7hiug0z83Dg8Gaxuvrqq2e9s0svXMz9fvTxWT9Ok+HSpW9mZX7vK+vPF/2GG77zq7HtT8Oz9PlLx3qsSJLUthtvuJyX7PmotmNoJZz4+cUr9bll4cKFA203KYXfCcAbI+JY4G+Av2TmH1rOJEmSJEmdMK7LOXwZeBawICKWAAcA8wEy89PASdSXclhMfTmHPcaRS5IkSZLuCcZS+GXmrjOsr4A3jCOLJEmSJN3TTMqsnpIkSZKkEbHwkyRJkqSOs/CTJEmSpI6blFk9JWnO++yJH+KWK3/fdgytpHs9fH1e+5L9244hSdJIWPhJ0pDccuXv2fv757QdQyvp8Ge3nUCSpNFxqKckSZIkdZyFnyRJkiR1nIWfJEmSJHWchZ8kSZIkdZyFnyRJkiR1nIWfJEmSJHWchZ8kSZIkdZyFnyRJkiR1nBdwlySpBecdvD/Lrvl92zG0ElZ/0Pps+vYPtR1DkmbFwk+SpBYsu+b3PG7RJW3H0Eq44Pzx7u/UI7/GrTdfMd6damjWuPdCnrvHzm3HkCz8JEmSJtmtN1/Bc1/65bZjaCWdevyubUeQAM/xkyRJkqTOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOs/CTJEmSpI6z8JMkSZKkjrPwkyRJkqSOW31cO4qIbYFDgXnAEZl5UN/69YGjgQc02+yXmSeNK58kSZIkddVYevwiYh5wGLAdsAjYNSIW9W32LiAz80nALsB/jCObJEmSJHXduIZ6PgVYnJkXZ+atwLHAjn3bVMD9m/trA1eMKZskSZIkddq4hnquA1zWs7wE+Ju+bd4DfDsi3gTcF3jeeKJJkiRJUreNq/Ar07RVfcu7Akdl5kcj4mnAFyJis8y8vXejiNgb2BsgM1mwYMGsw8yfP3/Wj9HkmD9//kr93ldlf5qbPFY0Gx4vGpTHimbD40WDGvWxMq7CbwmwXs/yutx9KOdewLYAmfmTiFgTWABc1btRZh4OHN4sVldfffWswyxdupQ1Z/0oTYqlS5eyMr/3Vdmf5iaPFc2Gx4sG5bGi2fB40aBW9lhZuHDhQNuNq/A7E9gkIjYELqeevOXlfdv8HngucFREPA5YE/jjmPJJkiRJUmeNZXKXzFwGvBE4BbigbsrzIuLAiNih2eytwGsj4mzgy8Dumdk/HFSSJEmSNEtju45fc02+k/ra3t1z/3zgGePKI0mSJEn3FOO6nIMkSZIkqSUWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEDFX4RYYEoSZIkSXPUoAXd5RHx0YjYfKRpJEmSJElDt/qA2+0EvAI4JSKuAr4AfDEzrxhZMkmSJEnSUAxU+GXm/wL/GxFvAbYDdgPeFRFnAF8EjsvMm0cXU5IkSZK0smZ17l5m3gac1dyuBDYG9gIui4iXDz+eJEmSJGlVDdTjFxH3B/4BeCXwBOCrwGsy8/Rm/VOBk4AvjSinJEmSJGklDXqO3x+AHwKHA1/vH9aZmWdExEnDDidJkiRJWnWDFn6bzDSRS2buNoQ8kiRJkqQhG/Qcv5dHxFa9DRHx5Ih46wgySZIkSZKGaNDCb1/gwr62CwELP0mSJEmacIMWfvcCbulr+ytw7+HGkSRJkiQN26CF3y+Af+xrey3wy+HGkSRJkiQN26CTu+wLfCciXgUsBh4FrAc8f1TBJEmSJEnDMVCPX2aeCzwa+DhwbvPzMZn5qxFmkyRJkiQNwaA9fmTmdcAXR5hFkiRJkjQCAxV+ETGP+hy/bYAFQJlal5nPGU00SZIkSdIwDDq5yyHAm4GfAn8DfBNYF/jRiHJJkiRJkoZk0MLvpcC2mflR4Lbm547A1iNLJkmSJEkaikELv/sAlzb3b4qIe2fmBcAWo4klSZIkSRqWQSd3uRDYCjgT+Dnw7oj4C3DFqIJJkiRJkoZj0MLvLcDtzf23Ap8B7ge8bhShJEmSJEnDM2Ph18zo+WjgKwCZ+WvgWaONJUmSJEkalhnP8cvM24BPZOYtY8gjSZIkSRqyQSd3+WZEbD/SJJIkSZKkkRj0HL/VgK9FxI+Ay4BqakVm7jmKYJIkSZKk4Ri08LsIOHiUQSRJkiRJozFQ4ZeZ/2/UQSRJkiRJozFQ4RcRWy9vXWaePrw4kiRJkqRhG3So53/2LT+4eeyVwPpDTSRJkiRJGqpBh3qu17scEasDBwBXjyKUJEmSJGl4Br2cw11k5jLgvcD+w40jSZIkSRq2lSr8Gs+m57IOkiRJkqTJNOjkLr/jrkXefYD7AW8aRShJkiRJ0vAMOrnLa/qWbwQuzMw/DzmPJEmSJGnIBi38Tgduz8zbphoiYl5ErN6c7ydJkiRJmlCDnuP3HeBv+tr+pmmXJEmSJE2wQQu/JwI/6Ws7A9h8uHEkSZIkScM26FDP64CHAFf1tD2E+ly/gUTEtsChwDzgiMw8aJptAngP9UQyZ2fmywd9fkmSJEnS9Abt8fsa8J8R8diIWCMiHgccAxw/yIMjYh5wGLAdsAjYNSIW9W2zCfV1AZ+RmZsC+wyYTZIkSZK0AoMWfv8KXAycBdwM/AL4HYNfwP0pwOLMvDgzbwWOBXbs2+a1wGGZeS1AZl6FJEmSJGmVDTTUMzNvBv4xIl4PPAz4v8y8fRb7WQe4rGd5CXefLObRABHxY+rhoO/JzJNnsQ9JkiRJ0jQGvYD7K4BzM/Mc4A9N2xOAzTLzSwM8RZmmrepbXh3YBHgWsC7ww4jYrP9agRGxN7A3QGayYMGCQV7CXcyfP3/Wj9HkmD9//kr93ldlf5qbPFY0Gx4vGpTHimbD40WDGvWxMujkLh8EntTXdjlwAjBI4bcEWK9neV3gimm2OSMzlwK/i4hfUxeCZ/ZulJmHA4c3i9XVV1890AvotXTpUtac9aM0KZYuXcrK/N5XZX+amzxWNBseLxqUx4pmw+NFg1rZY2XhwoUDbTdo4bc28Oe+tj8DDxzw8WcCm0TEhtQF4y5A/4yd/wXsChwVEQuoh35ePODzS5IkSZKWY9DJXS4A/q6vbQfgwkEenJnLgDcCpzTPlZl5XkQcGBE7NJudAvwpIs4Hvg+8PTP/NGA+SZIkSdJyDNrj9y/AN5rr7P0WeBTwQuAlg+4oM08CTupre3fP/QrYt7lJkiRJkoZkoB6/zDwdeAJwLvBg4BzgiU27JEmSJGmCDdrjR2ZeArx/ajki1o6IvZvJViRJkiRJE2rgwg8gIlYDtgVeRX0B9t9x5wybkiRJkqQJNOh1/J5AXey9ArgfMB/YJTO/PsJskiRJkqQhWGHhFxH7AK8GFgGnAm+nvuzCRcCPR55OkiRJkrTKZurxOwT4E/CKzDx+qrGe3FOSJEmSNBfMVPi9gHqI51ERcQjwZeBLQDXqYJIkSZKk4Vjh5Rwy87uZ+SrgYcABwFOAXzTLr4mIB4w+oiRJkiRpVQw0uUtm3ggcCRwZERtQ9wLuAfwrsNbI0kmSJEmSVtmsLucAd1zP70DgwIh4xtATSZIkSZKGaoVDPWeSmc7sKUmSJEkTbpUKP0mSJEnS5LPwkyRJkqSOs/CTJEmSpI4baHKXiJgPvBLYnL5ZPDNzzxHkkiRJkiQNyaCzeh4FbAV8A7h8ZGkkSZIkSUM3aOG3PbBRZl47yjCSJEmSpOEb9By/y1iJa/5JkiRJkto3aDF3JPDfEfEx4P96V2Tm6UNPJUmSJEkamkELv32bn4f0tVfA+sOLI0mSJEkatoEKv8xcb9RBJEmSJEmj4XX8JEmSJKnjltvjFxHnZubjm/u/ox7WeTeZudGIskmSJEmShmBFQz3f2HP/NaMOIkmSJEkajeUWfpn5g577p44njiRJkiRp2Aa+Nl9EbAY8E1gAlKn2zDxwBLkkSZIkSUMyUOEXEXsBnwBOBZ4PfAd4LnDi6KJJkiRJkoZh0Fk99wO2z8yXADc3PwO4cWTJJEmSJElDMWjh97DMPK25f3tErAZ8E9hpJKkkSZIkSUMzaOG3JCIe2dy/CHgR8FRg6UhSSZIkSZKGZtDJXT4KbAZcCrwfOA6YD7xlRLkkSZIkSUMyY49fRBTqyVxOBsjMbwAPBB6cmZ8YbTxJkiRJ0qoatMfvAuD+UwuZ+VfgryNJJEmSJEkaqhl7/DKzAs4GNh59HEmSJEnSsA3a4/dd4OSI+DxwGVBNrcjMY0YRTJIkSZI0HIMWfs8GLgde2NdeARZ+kiRJkjTBVlj4RcS6mbkkM585rkCSJEmSpOGa6Ry/88eSQpIkSZI0MjMVfmUsKSRJkiRJIzPTOX5Vcx2/5RaAmXn7cCNJkiRJkoZppsJvLWDZctYV6sld5g01kSRJkiRpqGYq/G4CNh1HEEmSJEnSaMxU+N2emZeOJYkkSZIkaSSc3EWSJEmSOm6mwm+7saSQJEmSJI3MCgu/zPzRuIJIkiRJkkZjph4/SZIkSdIcZ+EnSZIkSR1n4SdJkiRJHbfcyzlExA+pL9C+Qpm59VATSZIkSZKGakXX8TtibCkkSZIkSSOz3MIvM48eZxBJkiRJ0misqMfvDhFRgNcAuwILMvMJEbE18PDMzFEGlCRJkiStmoEKP+BA4PnAvwOfbtqWAB8DBir8ImJb4FBgHnBEZh60nO1eChwHPDkzfzZgPkmSJEnScgw6q+fuwIsz81junPDld8BGgzw4IuYBhwHbAYuAXSNi0TTb3Q94M/C/A+aSJEmSJM1g0MJvHnBDc3+q8Furp20mTwEWZ+bFmXkrcCyw4zTbvQ/4MPDXAZ9XkiRJkjSDQQu/k4BDIuJecMc5f+8DThzw8esAl/UsL2na7hARTwLWy8xvDPickiRJkqQBDHqO377AMcBfgPnUPX3fBl414OPLNG13XCMwIlajPl9w95meKCL2BvYGyEwWLFgwYIQ7zZ8/f9aP0eSYP3/+Sv3eV2V/mps8VjQbHi8alMeKZsPjRYMa9bEyUOGXmdcBO0XEw4D1gcsy88pZ7GcJsF7P8rrAFT3L9wM2A06LCICHAydExA79E7xk5uHA4c1idfXVV88iRm3p0qWsOetHaVIsXbqUlfm9r8r+NDd5rGg2PF40KI8VzYbHiwa1ssfKwoULB9puuYVf0wvX74/N7Y71mXn7APs5E9gkIjYELgd2AV4+tTIz/wLcUd5GxGnA25zVU5IkSZJW3YrO8VsGLB3gNqPMXAa8ETgFuKBuyvMi4sCI2GHl40uSJEmSZrKioZ4b9tx/EfBS4EPApcAjgX8BvjrojjLzJOpJYnrb3r2cbZ816PNKkiRJklZsuYVfZl46dT8i9gW2ysw/N02/iYifAT8DPjXaiJIkSZKkVTHo5RzWBu7T13afpl2SJEmSNMEGvZzD0cB3I+Lfqa/Htx7w5qZdkiRJkjTBBi383gEsBl4GLAT+AHwS+OyIckmSJEmShmTQ6/jdDny6uUmSJEmS5pBBe/yIiD2AVwLrUF+L7wuZeeSogkmSJEmShmOgyV0i4p3AfsCx1Of2HQu8o2mXJEmSJE2wQXv8XgM8q+8SD6cApwMfGEUwSZIkSdJwDHo5h/sCf+xr+xNw7+HGkSRJkiQN26A9ficD/xkR+wG/Bx5J3dN3yqiCSZIkSZKGY9AevzcC1wNnAzcAZwE3Am8aUS5JkiRJ0pAMejmH64BXRcTuwALg6uYSD5IkSZKkCbfCwi8i1l/OqnUjAoDM/P2wQ0mSJEmShmemHr9LgKq5X6ZZXwHzhhlIkiRJkjRcM53jdw5wEfAu6gld5vfd1hhpOkmSJEnSKlth4ZeZmwMvBR4E/Ag4CdgFWCMzb8vM20YfUZIkSZK0Kmac1TMzf5WZbwc2BA4BXgz8ISK2GHU4SZIkSdKqG/RyDgCbANsATwN+CVw7kkSSJEmSpKGaaVbPBwG7Aq8G7gd8AdjamTwlSZIkae6YaVbPK4DfURd8ZzRtj4qIR01tkJnfG1E2SZIkSdIQzFT4XQmsCby2ufWrgI2GHUqSJEmSNDwrLPwyc4Mx5ZAkSZIkjchsJneRJEmSJM1BFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEln8BhrAAAgAElEQVSS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxFn6SJEmS1HEWfpIkSZLUcRZ+kiRJktRxq49rRxGxLXAoMA84IjMP6lu/L/AaYBnwR2DPzLx0XPkkSZIkqavG0uMXEfOAw4DtgEXArhGxqG+zXwJbZeYTgOOBD48jmyRJkiR13bh6/J4CLM7MiwEi4lhgR+D8qQ0y8/s9258B7DambJIkSZLUaeM6x28d4LKe5SVN2/LsBXxrpIkkSZIk6R5iXD1+ZZq2aroNI2I3YCtgm+Ws3xvYGyAzWbBgwazDzJ8/f9aP0eSYP3/+Sv3eV2V/mps8VjQbHi8alMeKZsPjRYMa9bEyrsJvCbBez/K6wBX9G0XE84B3Attk5i3TPVFmHg4c3ixWV1999azDLF26lDVn/ShNiqVLl7Iyv/dV2Z/mJo8VzYbHiwblsaLZ8HjRoFb2WFm4cOFA242r8DsT2CQiNgQuB3YBXt67QUQ8CfgMsG1mXjWmXJIkSZLUeWM5xy8zlwFvBE4BLqib8ryIODAidmg2OxhYCzguIs6KiBPGkU2SJEmSum5s1/HLzJOAk/ra3t1z/3njyiJJkiRJ9yTjmtVTkiRJktQSCz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6jgLP0mSJEnqOAs/SZIkSeo4Cz9JkiRJ6rjVx7WjiNgWOBSYBxyRmQf1rb8XcAywJfAn4GWZecm48kmSJElSV42lxy8i5gGHAdsBi4BdI2JR32Z7Addm5qOAjwH/No5skiRJktR14xrq+RRgcWZenJm3AscCO/ZtsyNwdHP/eOC5EVHGlE+SJEmSOmtchd86wGU9y0uatmm3ycxlwF+AB48lnSRJkiR12LjO8Zuu565aiW2IiL2BvQEyk4ULF846zH+d9H7g/bN+nO6ZFh797bYjaI744AH/DQe0nUIr64Nj3t/Co78/5j1qWDYY8/72ev8HGf8RqmHZa/Px7u/VbztqvDvU0Lz6baN9/nH1+C0B1utZXhe4YnnbRMTqwNrANf1PlJmHZ+ZWmbkVdbHore8WET9vO4O3uXHzWPE2m5vHi7dBbx4r3mZz83jxNujNY2WFtxmNq8fvTGCTiNgQuBzYBXh53zYnAK8GfgK8FPheZt6tx0+SJEmSNDtj6fFrztl7I3AKcEHdlOdFxIERsUOz2eeAB0fEYmBfYL9xZJMkSZKkrhvbdfwy8yTgpL62d/fc/yvwD+PK03GHtx1Ac4bHimbD40WD8ljRbHi8aFAeK6ugVJWjKSVJkiSpy8Y1uYskSZIkqSUWfpIkSZLUcRZ+0j1IRJSIeETbOSRJkjReFn4dEBHzIuItbefQ5GsukfKNtnNo8kXEw9rOIKmbImK1iIi2c2iyRcSTI2K7adp3iIgt28g0141tVk+NTmbeFhE7Ah9rO4vmhJ9GxBaZ+Yu2g2iinR0R5wJfBr6amX9pO5AmU0SsCbwMuBY4EXgH8Ezgt8D7MvPqFuNpAmXm7RHxRiDbzqKJdjCw+zTt51PP7vmcsabpAAu/7vhxRHwS+Apw41SjH+41jb8FXhsRv6U+VgpQZeYW7cbShFkHeB6wC/ChiPgJdRF4Qmbe3GoyTZpjgKXAfYG3Ar8CPkn9t+Yo4MWtJdMk+05EvI27f265pr1ImjAPzsxL+hszc3FEPLiFPHOehV93PL35eWBPW4Xfhujudmo7gCZfZt4GnAKcEhFrANtRF4GHRsSpmfmKVgNqkizKzM0iYnVgSWZu07SfHBFntxlME23P5ucbetoqYKMWsmgy3XsF6+47thQdYuHXEZn57LYzaG7IzN9GxFOBR2fmMc23Zv4B1XJl5q0RcT5wAbAlsKjlSJostwJk5rKIuKJv3W0t5NEckJkbtp1BE++7EfEB4F3NHAUARMR7ge+1F2vusvDriGYihg8CCzNzu4hYBDwtMz/XcjRNmIh4F/AMYGPqIVprAl+iHpYl3SEi1qc+d2tX6i8HjgV2zMwLWg2mSbNuRHycetj41H2a5XXai6VJFhH3AfYF1s/MvSNiE+AxmekEZJryVuBzwOKIOKtpeyLwM+A1raWawyz8uuMo4Ejgnc3yb6jHzVv4qd9LgScBvwDIzMsj4v7tRtKkiYj/of7Qfhywd2b+rOVImlxv77nff5x43Gh5jgR+zp2nqiyh/ntj4ScAMvNGYJeI2AjYtGk+LzMvbjHWnGbh1x0LMjMjYn+4Y8iNQ2w0nVsys4qICu741lXqtz9weu/wGmk6mXl02xk0J22cmS+LiF0BMvPmiChth9LkaE4x+CLwlcw8se08XWDh1x03NudqTX2Yfyrg9Ouaztci4jBg7YjYA9gL+HzLmTR5XgQ8Dvh0b2NzzdCHZ+a/tJJKEycijqT5v2caVWbuNc48mjNujYh7c+fnlo2BW9qNpAmzK/WkYt+OiKupZ5bOzOw/l1gDsvDrjn2BE4CNI+LHwEOoh/RJd5GZ/9ZcEPVW6rHyH8jMb7UcS5PnxcBm07QfCpwDWPhpynRD89YH9gHmjTmL5o4DgJOB9SLiP6nPPd+91USaKJl5NnA2sH/TofEy4IyIWAx8OTM/22rAOahUlaN4uqKZSvsx1CfU/zozl7YcSdIcFRHnZeams12ne7bmXJx/BbYGPgZ8LjNvbTeVJlUzUump1J9bzsjMq1uOpAkXEc+i/tuyKDPv1XKcOccevzkuIp6Tmd+LiJ37Vj06IsjMr7USTBMnIn6QmdtExLXcdVjW1AXcH9RSNE2mmyJik8y8qLexmXnPC7jrLiLicdSTiz0JOBh4XWYuazeVJlFEPDYzL4yILZqmPzQ/14+I9TPzF21l02SKiCdTD/v8e+AS4HDqiYA0SxZ+c9/W1Ncyeck06yrAwk9T9mh+Lmg1heaKdwPfioj3U8+8B7AV9aQv+7SWShMnIo6jPjY+AryF+tp9948IADLzmvbSaQLtC+wNfHSadRXwnPHG0aSKiA8CAfyZ+nJCz8jMJe2mmtss/Oa+a5ufn8vMH7WaRJPuOOqLb38rM1/QdhhNtsz8VkTsRD1V/5ua5vOAv8/Mc9tLpgn0ZOoP7G+jvu5W78yMFbBRG6E0sb7T/NzLafk1g82BPTPzdICIeFVE/D1wKfAev1SaPQu/uW8P6skWPg5sMcO2umebFxHvBB4XEW/uX5mZH5/mMboHy8xfAa9uO4cmW2Zu0HYGzSn7U38ReTx+btGKPRz4FUBEbA0cRP1F5ObUwz2dxHCWLPzmvgsi4hLgIRFxTk/71HlbT2gnlibQrsDO1P/uH9JyFs0REfFo6p6cDej5PyMzHY6lu4mIdYBHctdj5fT2EmkC/Skivg9sGBEn9K/MzB1ayKTJtFpPr97LgMMz86vAVyPirBZzzVkWfnNcZu4aEQ8HTgH8Y6nlyswLgA9ExDleCFWzcBz1tfyOoD53S5pWRPwb9Yez87nzWKkACz/1ehF1T98XmP48P2nK6hGxejNR1HOpzw29Y11LmeY037QOyMwrqa/HJi1XROyamV8GNnKop2ZhWWZ+qu0QmhN2Ah6TmV6EW8vVXN7jjIh4emb+se08mmhfBn7QXLz9ZuCHABHxKOAvbQabqyz85riIyMyMiDiX6afod6inpjyw+emsnpqNEyPin4CvA3d8oPekek3jYmA+PceJ1C8i/j0z9wE+HxF3u5i0Qz01JTM/EBGnAo8Avp2ZU8fLatw56ZhmwcJv7vvn5ueLW02hiZeZ/9H8/H9tZ9GcMjW5y9t72pypUdO5CTir+aDW+yXB3UYY6B7tC83Pj7SaQnNCZp4xTdtv2sjSBaWq7vZli+agiLgvcHNm3t5MxvBY6mn7l7YcTRMmIj4EfIj6Q9o3qWfHektmfqnVYJLmtIiYdgbYzDx63Fk0t0TEA4H1MvOcGTeWtNLs8euO04FnNn88TwV+Rn2S/StaTaVJtF1m7t9co+0qYDPgu4CFn+4mIuYDrwe2bppOAz7jl0rqZ4Gn2YiI06gnpVsdOAv4Y0T8IDP3bTWY1GGrtR1AQ1My8ybq6fo/kZl/ByxqOZMm09QXPtsDX25OrrfrX8vzKWBL4D+a25ZNm3QXEbFJRBwfEedHxMVTt7ZzaWKtnZnXUX9uOTIztwSe13ImqdPs8euOEhFPo+7h26tp8/er6XwrIn5FPd36GyJiAU7GoOV7cmb2zhr8vYg4u7U0mmRHAgcAHwOeDexBPdGYNJ3VI+IRQADvbDuMdE9gj1937APsD3w9M8+LiI2A77ecSRMoM98OPAfYshmudzP1N67SdG6LiI2nFpq/LV7PT9O5d2aeSj0C5dLMfA/13xppOgdSX4N4cWae2fxtuajlTFKnOblLB0XEasBazRAK6S4iYmfgO5l5fUTsR30h3Q9m5lktR9MEiojnUvfkXEzde/NIYI/M9Isl3UVE/Bh4JnA88D3gcuCgzHxMq8EkSYBDATsjIr4EvI76m/ifA2tHxCGZeXC7yTSB3pOZX4uIpwMvAQ4BPg08td1YmkSZeWpEbAI8hrrwu9ALdGs59gHuA7wZeB91b9+0M31KEfFh4P3Uo05OBp4I7JOZX2w1mNRhDvXsjkVND99OwEnA+sAr242kCTU1TO/FwH9k5leBe7WYRxMoIp7T/NwZeBHwKGBj4EVNm3QXmXlmZt6QmUsyc4/M3Hm6a3BJjRc0n1teDCwBHs1drxcqacjs8euO+c206zsBn8zMpRHhOF5N5w8RcRiwLbBVRKyBXwLp7rahHq73kmnWVcDXxhtHkyoi/j0z94mIE5lmhuDM3KGFWJp885ufUzNMXxMRbeaROs/Crzs+A1wCnA2cHhGPBDzHT9MJ6v9oP5GZ10bEQmC/ljNpwmTmAc3PPdrOoon3hebnR1pNobnmxIi4kHqo5z9FxEOAv7acSeo0J3fpsIhYPTOXtZ1DkykiHgSsObWcmVe0GEcTKiL+mXpyl+uBz1JPBrRfZn671WCaaBHxQGC9zDyn7SyaXM1xcl1m3hYR9wHun5lXtp1L6ip7/DokIl4EbErPh3nq6ZKlOzTHyceAdYE/AQupp9B+bJu5NLH2zMxDI+KFwEOpr812JGDhp7uIiNOAHag/W5wF/DEifpCZ+7YaTJNsHeD5EdH7ueWYtsJIXed5PR0REZ8GXga8iXrmvX+gnnZd6vcB4BnArzNzPepz/U5rNZEm2dQFuLcHjszMs/Gi3Jre2s1kHTtTHytbAs9rOZMmVEQcAHyiuT0b+DD1FweSRsTCrzuenpmvAq7NzPcCTwPWazmTJtOyzPwjsFpElMz8DvXwPWk6P4+Ib1MXfqdExP2A21vOpMm0ekQ8gvo84m+0HUYT76XAc4Erm3OJn4gzTEsjZeHXHTc3P29qJutYCmzYYh5Nrr9ExH2BHwHHRMRH8YO8lm8v6sl/npyZN1HPxOeEL5rOgcApwOLMPDMiNqIeRi5N5+bMvB1YFhH3B64CNmo5k9RpnuPXHd+IiAcABwO/oJ5S+4h2I2lC7QTcQn2x5VcBazP9lP0S1KMHzsrMGyNiN+re4UNbzqQJlJnHAcf1LF8M/H17iTThftZ8bvks8HPgBuCn7UaSus1ZPTsoIu4FrJmZf2k7i6S5LSLOoR6C9QTqafs/B+ycmdu0GkwTJyI+DLyfegTKydTHzT6Z+cVWg2niRcQG1DN6OgusNEL2+M1xEbHzCtaRmV5kWQBExLVMc3Fl6ok6qsx80JgjaW5YlplVROwIHJqZn4uIV7cdShPpBZn5joj4O2AJ9SRj3wcs/HSHiFjuOeURsUVm/mKceaR7Egu/uW9FQ/QqwMJPUxa0HUBz0vURsT/wSuCZETGP+jw/qd/UcbE98OXMvCYi2syjyfTRFayrgOeMK4h0T2PhN8c1M2FJg9gcWJCZp/Q2Ntf1uwL4ZSupNOleBryc+np+V0bE+tTnEkv9ToyIC6mHev5TRDwE+GvLmTRhMvPZbWeQ7qmc1XOOi4h9I2KvadrfFBH7tJFJE+tgpp9h7yLgI2POojkiM68Evsqd06xfDXy9vUSaVJm5H/VkQFtl5lLgRmDHdlNp0kTEbhHxymnaXxsRL28jk3RPYeE39+1JPeFCv8ObddKUhzSz7N1FZv4GeEgLeTQHRMRrgeOBzzRN6wD/1V4iTaqIeBX16QevaO6/FHhBu6k0gd7K9H9DvtKskzQiFn5zX5WZt/Y3ZuYt1JN2SFPuvYJ19xlbCs01bwCeAVwHkJkXAQ9tNZEm1ZN7bs8E3gPs0GYgTaR5mXl9f2NmXofnD0sjZeHXARHxsEHadI/3vYh4b39jRLwbOG38cTRH3NL75VJErM70s8PqHi4z39Rzey3wJGCNtnNp4syPiPv2N0bE/fB4kUbKyV3mvoOBb0bEW6kv3A6wJfBhPG9Ld/VW4PMR8RvunMhlc+BcwEmCtDw/iIh/Be4dEc8H/gk4seVMmhtuAjZpO4QmzueA4yPi9Zl5CdxxHb/DmnWSRsQLuHdARGwH7AdsRv1N/HnAQZn5rVaDaSJFxKOBTZvF85pz/KRpRcRqwF7U52oV4BTgiMz0Pw/dRUScyJ29wasBi4BsJn2R7hARrwP2B9aiPmZupP7c8qlWg0kdZ+HXERHxt5n5o762Z2Tmj9vKpMkVEbsCG2XmByJiPeChmfnztnNpsjTX7Ds6M3drO4smX0Rs07O4DLg0M5e0lUeTLyLWAsp05/xJGj6HenbHx4Et+to+MU2b7uEi4pPUJ9BvDXyA+pvWT1NPyCDdITNvi4iHRMQa000iJfXKzB+0nUFzR0T8M3AkcH1EHEH9eWW/zPx2u8mk7rLwm+Mi4mnA04GHRMS+PavuD8xrJ5Um3NMzc4uI+CVAZl4TEZ5Qr+W5BPhxRJxA/SUBAJl5SGuJNJEi4qnUXzg+jnqSjnnAjZl5/1aDaVLtmZmHRsQLqWcK3oO6ELTwk0bEWT3nvjWox8ivDtyv53Yd9TWUpH5Lm/O2KoCIeDBwe7uRNMGuAL5B/f9F798Yqd8ngV2Bi6gvH/Ma6kJQms7UJae2B47MzLPxMlTSSNnjN8c1Q2t+EBFHZealcMdkDGs118SR+h0GfJW6l/i9QAB3u8yDBJCZHhsaWGYujoh5mXkbcGRE/E/bmTSxfh4R3wY2BPZvLufgl5DSCDm5S0dExJeA1wG3AT8H1gYOycyDWw2miRQRm/L/27v3uM3nOo/jr3ucwg5GVIsG2Q5bj0xODbGi0iJiS+/IIcIKldOK9qFVSaLIJnZbZZLTPt5KknVKOSyLcioJFWZSjXI2pDHGvX98fxeX20xmhrm/v+t3v5+Px/24ru/vd123t7r9ruvz+57gXZS7q5fa/kXlSNFSI1Zq7HkEuB74uu2/jH6qaCNJV1KuK98Epjc/u9qeVDVYtI6kIWAVYEXgLtsPN6NPVrb987rpIrorQz27441ND9+2wAXARGDnupGixcYDD9k+HpguaWLtQNFadwGPASc3P48CfwRe17QjenamfK/YlzIfdBXg/VUTRSs128Gca/tG2w83xx5I0RexcGWoZ3csJmkxSuH3NduzJKU7N55H0mHAhsAawLeBlwFnAhvVzBWttZbtjfvaP5B0pe2NJd1aLVW0hqRtgFVsn9i0r6As1jEMXAP8pmK8aK9rJa1n+6e1g0SMFenx646vU1bfWxq4UtKqlDvzESNtR5lM/ziA7d9TVoGNmJMV+3uEm+crNM1s8RAAnwTO62svAawDbALsXSNQDIRNKcXfnZJ+LukWSenxi1iI0uPXEba/StnLr2eapE1r5YlWm2l7uNcjLGmp2oGi1Q4CrpJ0J2VO6OrAPpKWBk6tmizaYnHb9/S1r7L9IPBg83cSMSdb1A4QMdak8OsISa8EvgCsZHsLSW8ENqBMso/od46kE4FlJe0G7A6cUjlTtJTtCyS9FngDpfC7vW9Bl+PrJYsWmdDfsP2xvuaKo5wlBoTtaZImAf/QHPrfZkuHiFhIMtSzO74FXAys1LR/BexfLU20lu2jKfuynQdMAo5sFnmJeJ6mR/hg4GO2bwZeLWmryrGiXa6TtOfIg5L2An5SIU8MAEn7AWdQ5oO+Ajhd0sfrporotvT4dccKti3pUwC2n5I0u3aoaBdJiwAX2P5H4MLaeWIgTKFsEbNB0/4dcDbl5kEEwAHAuZI+BNzYHFuHMtdv22qpou12BybbfhxA0tGUxYBOqJoqosPS49cdjzd74PTmba1P2Wsr4hnNpspPSspiLjGv1rB9DDALwPYTlCGfEQDY/pPttwFHUBYZmwp8zvYGtv9YM1u02hBl7+Ge2eTaErFQpcevOw6kDN1bQ9LVlHkV29WNFC31GPAzSZfQrOwJYPvAepGixZ6UtCTP3lRaA5hZN1K0ke0fAz+unSMGxhTKMOHvUQq+bci6BBELVQq/DpA0jrIX29uB11MuoHfYnlU1WLTVpc1PxLw4HLiIMrfvDMoekLtWTRQRA8/2cZIu59k9ZHezfVPFSBGdNzQ8nD2+u0DSNbY3eOFXxlgl6Vu2d62dIwZPM4x8fcpNpWtt3185UkR0gKS1Kat6Pg1cbfvGF3hLRLwImePXHZdIer+kjI+PuVmzdoAYTLYfsP0/ts8HXi7p5NqZImKwSfo3yl6gE4AVgCmSDqubKqLbMtSzOw4ElgZmS+otvjBsO4t4RM9SktZiLpPnc6c1+klaE/gyZYuYcykr7Z0ETAaOrRgtIrphB2Ct3r6gkr5IWRX281VTRXRYCr+OsD2+doZovZUpX9jnVPgNA+8Y3TjRcicD/0FZXn1zyheyM4Ed+zZwj4hYUFMp6xP0ridLAHdWSxMxBqTw6xBJ7wU2bpqXN8OyInp+YzvFXcyrJWx/q3l+h6R/AQ5ttgSJiFggkk6g3GycCdwq6YdNezPgqprZIrouhV9HNEMk1gPOaA7tJ2kj24dWjBURg+tlI4YGPwas2ZtHnKHBEbGArm8ebwC+13f88tGPEjG2pPDrji2Bt9h+GkDSqcBNQAq/6DmkdoAYKNOB4/ra9/a1MzQ4IhaI7VNrZ4gYq1L4dctywIPN82VrBon2sX0JgKQNgc8Aq1KuAb2FgF5TL120je1Na2eIiO7KZ1HE6Evh1x1HATdJuoxy8dwY+FTdSNFS3wQOoAyzyXyt+Ksk7QucYfvhpj0B2MH2SXWTRcSAy2dRxChL4dcRts+SdDllnt8QcIjte+umipZ6xPaFtUPEwNjT9om9hu2HJO1J2dohImJB5bMoYpSl8Btwkj5m+2tNc3nb51UNFIPgMklfAs6hrKoGZLGOmKtxkoZsDwNIWgRYvHKmiBhQktZunuazKGKUpfAbfB8BeoXfacDaf+W1EVA24AZYt+9YFuuIubkYsKT/pPydfBS4qG6kiBhgx45o57MoYpSk8OuWOW3MHfEcWbQj5tMhwF7A3pRrzCXAN6omioiBlc+giHqGhoeHa2eIF0HSXcBBwDjgGODg/vO2z6mRK9pL0rLA4ZQFgACuAD5n+5F6qSIiYiyRdOAcDj8C3GD75tHOEzEWpMdv8F0BvLd5fiWwdd+5YcrY+Yh+pwC/ANS0dwamAO+rlihaR5JtS9ItlGvJc9hes0KsiOiOdZufHzTt9wA/BT4q6Wzbx1RLFtFRKfwGnO3dameIgbOG7ff3tT8rKXdXY6T9msetqqaIiK56ObC27ccAJB0OfIcyGuUGyiimiHgJpfDrCEnLAbsAq9H3/6vtT9TKFK31hKSNbF8Fz2yi+0TlTNEytqc3T/exfUj/OUlHU+b+RUQsqInAk33tWcCqtp+QNHMu74mIFyGFX3dcAFwL3AI8XTlLtNvewKnNXL8h4EFg16qJos024/lF3hZzOBYRMT/OBK6V9P2mvTVwlqSlgV/WixXRXVncpSMk3Wg7WznEPJO0DIDtR2tnifaRtDewD7AG8Ju+U+OBq23vVCVYRHSGpHWAjSg3Ia+yfX3lSBGdlsKvIyQdADwGnM9zN0J9sFqoaBVJO9k+fS4rqWH7uNHOFO3V9AhPAI4CDu07NSPXlYhYUJKWsf2opOXndD7Xl4iFZ1ztAPGSeRL4EnANZVL0DUDunEW/pZvH8XP5iXiG7UdsTwUOA+61PQ1YHdipmVMcEbEgzmwee99TRj5GxEKSHr+OkHQnMNn2/bWzRER3NCu+rktZOOpi4Dzg9ba3rJkrIiIi5k8Wd+mOW4E/1w4R7SfpGODzlJU8LwImAfvbPr1qsGirp20/Jel9wPG2T5B0U+1QETHYJA0BOwKr2z5C0kTgVbZ/UjlaRGel8OuO2cDNki7juXP8sp1DjPRu25+U9E/A74APAJcBKfxiTmZJ2oGyXczWzbHFKuaJiG44ibIK+TuAI4AZwHeB9WqGiuiyzPHrjnOBI4H/49k5fjdUTRRt1fvSviVwVibSxwvYDdgAONL23ZJWJzcJIuLFm2x7X+AvALYfAhavGymi2zLHr0V4tjUAAAn5SURBVEMkLQ68rmneYXtWzTzRTpK+CGxLGer5VmA54Hzbk6sGi4iIMUPSdcDbgJ/aXlvSisAltteqHC2is1L4dYSkTYBTgamU/XBeDXzY9pUVY0VLSZoAPGp7tqSlgGVs31s7V7SHJNuWpFuA531Q2F6zQqyI6AhJOwIfBNamfH/ZDjjM9tlVg0V0WOb4dcexlLlbdwBIeh1wFrBO1VTRGpLeYfvHzSIdvWP9Lzln9FNFi+3XPG5VNUVEdJLtMyTdALyTcsN6W9u3VY4V0Wkp/LpjsV7RB2D7V5KyAEP0ezvwY55doKPfMCn8oo/t6c3jtNpZIqKbbN8O3F47R8RYkaGeHSHpFMqX99OaQzsCi9rerV6qiBh0kmbw/KGej1A2Wj7I9l2jnyoiBtWIa8pQ3/NFgcVtp1MiYiHJf1zdsTewL/AJyoX0SspSyRHPIekLwDG2H27aEyhf4A+rmyxa6jjgD8CZlGvL9sCrgDuAU4BNqiWLiIFje3x/W9J4YB9gL+B7VUJFjBHp8YsYYyTdNHLVNEk32l67VqZoL0nXjVzxVdK1tteX9DPbk2pli4jBJWk5YH/KHqFnAl+x/UDdVBHdlh6/ATe3Ffd6svJezMEikpawPRNA0pLAEpUzRXs9rbIK0Hea9nZ953LnMCLmi6QVgIMoK3qeAqxl+5G6qSLGhhR+g6+34t6+zWP/HL8/j36cGACnAz+SNIXyxf0jlKW0I+ZkR+DfeXbo+DXATs0Ng49VSxURg2oacB8whfI9Zff+FaZtH1cpV0TnZahnR0i62vaGL3QsAkDS5sC7KHO2LrF9ceVIERExBkj6DHMfLTBs+3OjGCdiTEmPX3csLWkj21cBSHobsHTlTNFetwFP2b5U0lKSxtueUTtUtI+kVYATgA0pX9auAvaz/buqwSJiUH1jbtcPSXPabigiXiLjageIl8zuwImSpkqaShmW9ZG6kaKNJO1Jma/19ebQysC59RJFy00BzgNWovyt/KA5FhGxIH4kabWRByXtBhw/+nEixo70+HWE7RuASZKWAYYyUTr+in2BtwLXAdj+taRX1I0ULbai7f5C71uS9q+WJiIG3QHADyVtafvXAJI+BXwIeHvVZBEdl8KvIyQtAbwfWA1YtDdROmPlYw5m2n6y9zciaVGyOmPM3f2SdgLOato7AFlyPSIWiO0LJM0ELpS0LbAHsB6wse2H6qaL6LYM9eyO7wPbAE8Bj/f9RIx0haR/BZaUtBlwNmX4XsScfAQQcC8wnbKdw25VE0XEQLP9I2BX4HLgNcA7U/RFLHzp8euOVWxvXjtEDIRDKXNCbwH2Ai4AvlE1UbSW7d8C7+0/1gz1zFyciJhvkmZQRpkMUfaQfSfwJ0lDlFU9l6mZL6LLsp1DR0j6L+AE27fUzhLtJ2lFANv31c4Sg0fSb21PrJ0jIiIi5l16/LpjI2BXSXcDMyl30oZtr1k3VrRFczf1cMqm20PAkKTZlBsGmQsa82OodoCIiIiYP5nj1x1bAK8F3g1sDWzVPEb07E/Zi2092y+3vTwwGdhQ0gF1o8WAyVCRiIiIAZMev46wPQ2gWZb/ZZXjRDvtAmxm+/7eAdt3NSs2XgJ8pVqyaJ2+eTgjDQFLjnKciIiIeJFS+HWEpPcCx1I2Wf4TsCpwG/CmmrmiVRbrL/p6bN8nabEagaK9bI+vnSEiIiJeOhnq2R1HAOsDv7K9OmWVrKvrRoqWeXIBz0VERETEgEuPX3fMsv2ApHGSxtm+TNLRtUNFq0yS9Ogcjg+R4cERERERnZbtHDpC0qXAtsBRwAqU4Z7r2X5b1WAREREREVFdhnp2xzbAn4EDgIuAO8mqnhERERERQXr8OkvSIsD2ts+onSUiIiIiIurKHL8BJ2kZYF9gZeA84IdN+2DgZiCFX0RERETEGJfCb/CdBjwEXAPsQSn4Fge2sX1zzWAREREREdEOKfwG32tsvxlA0jeA+4GJtmfUjRUREREREW2RxV0G36zeE9uzgbtT9EVERERERL8s7jLgJM0GHm+aQ8CSlNU9h4Bh28vUyhYREREREe2Qwi8iIiIiIqLjMtQzIiIiIiKi41L4RUREREREdFxW9YyIiDFN0mrA3cBitp96gdfuCuxhe6NRiBYREfGSSeEXEREDQ9JUYCVgJdv39x2/GZgErG57aqVsq1EKyAtsv6fv+OnAb2x/pkauiIgIyFDPiIgYPHcDO/Qakt5MWdG4LdaXtGHtEBEREf3S4xcREYPmNGAX4ISm/WHg28Dney+QtGxzfgvKFjcnA1+w/bSkRYCjgV2BR4Fj+395897jgC2Bp4EpwOHNXqnz4pgmy6YjT0ia0OSfTPkMvhr4qO3fNecvB64C3gGsCVzW5PwqsDVwB/CBXq+mpDc0/57rAPcBn7btecwZERFjSHr8IiJi0FwLLCPp75si7oPA6SNecwKwLPAa4O2UQnG35tyewFbAWsC6wHYj3nsq8BTwd81r3g3sMR/5TgReJ+ldczg3jlJIrgpMBJ4AvjbiNdsDOwMrA2sA1zTvWR64DTgcQNLSwA+BM4FXUHpBT5L0pvnIGhERY0R6/CIiYhD1ev2uAG4Hft870VcMrmV7BjBD0rGUYuqbgIDjbd/TvP4oYJPm+SspvYTL2X4CeFzSV4B/Br4+j9n+AhxJ6fW7tP+E7QeA7/ZlPZLSq9dviu07m/MXAm+0fWnTPhs4onndVsBU21Oa9o2SvkspZG+dx6wRETFGpPCLiIhBdBpwJbA6ZZhnvxWAxYFpfcemUXrQoCwOc8+Icz2rAosB0yX1jo0b8fp5cTJwsKSt+w9KWgr4CrA5MKE5PF7SIn1DSf/Y95Yn5tD+m76skyU93Hd+Ucr/NhEREc+Rwi8iIgaO7WmS7qbMw9t9xOn7gVmUwuiXzbGJPNsrOB14dd/rJ/Y9vweYCazwQls7vEC+WZI+S+md6+99Owh4PTDZ9r2S3gLcBAwtwD/mHuAK25staM6IiBg7UvhFRMSg2h2YYPtxSc98ntmeLcnAkZJ2ocyNOxD4cu8lwCcknQ88Dhza997pki4BjpX0aeAxSq/iKravmM98pwGHUHr3ft0cG0/ptXtY0vI08/UW0PnAFyXtDPx3c+wtwGO2b3sRvzciIjooi7tERMRAsn2n7evncvrjlKLuLsoqmWcCpzTnTgYuBn4G3AicM+K9u1CGiv4SeAj4DvC3C5BvNqWwW77v8PGUrSfupyxSc9H8/t6+3z+DsvDM9sAfgHspq5UusaC/MyIiumtoeHi4doaIiIiIiIhYiNLjFxERERER0XEp/CIiIiIiIjouhV9ERERERETHpfCLiIiIiIjouBR+ERERERERHZfCLyIiIiIiouNS+EVERERERHRcCr+IiIiIiIiOS+EXERERERHRcf8POVW4OSSsC6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "sns.barplot(x=\"Model Name\", y=\"Model Train Accuracy\",data=Model_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Model Train Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
