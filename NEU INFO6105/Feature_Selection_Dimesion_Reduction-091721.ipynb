{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "train=pd.read_csv(\"/Users/pramodgupta/Desktop/Courses_0921/ML_Python/Scripts/Big-Mart-Sales-Prediction-master/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Ratio\n",
    "\n",
    "Suppose we’re given a dataset. What would be your first step? You would naturally want to explore the data first before building model. While exploring the data, you find that your dataset has some missing values. Now what? You will try to find out the reason for these missing values and then impute them or drop the variables entirely which have missing values (using appropriate methods).\n",
    "\n",
    "What if we have too many missing values (say more than 50%)? Should we impute the missing values or drop the variable? I would prefer to drop the variable since it will not have much information. However, this isn’t set in stone. We can set a threshold value and if the percentage of missing values in any variable is more than that threshold, we will drop the variable.\n",
    "\n",
    "Now, we will check the percentage of missing values in each variable. We can use .isnull().sum() to calculate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  1463\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               0.000000\n",
       "Item_Weight                  17.165317\n",
       "Item_Fat_Content              0.000000\n",
       "Item_Visibility               0.000000\n",
       "Item_Type                     0.000000\n",
       "Item_MRP                      0.000000\n",
       "Outlet_Identifier             0.000000\n",
       "Outlet_Establishment_Year     0.000000\n",
       "Outlet_Size                  28.276428\n",
       "Outlet_Location_Type          0.000000\n",
       "Outlet_Type                   0.000000\n",
       "Item_Outlet_Sales             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the percentage of missing values in each variable\n",
    "train.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above table, there aren’t too many missing values (just 2 variables have them actually). We can impute the values using appropriate methods, or we can set a threshold of, say 20%, and remove the variable having more than 20% missing values. Let’s look at how this can be done in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Fat_Content              object\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Outlet_Size                   object\n",
       "Outlet_Location_Type          object\n",
       "Outlet_Type                   object\n",
       "Item_Outlet_Sales            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving missing values in a variable\n",
    "a = train.isnull().sum()/len(train)*100\n",
    "# saving column names in a variable\n",
    "variables = train.columns\n",
    "variable = []\n",
    "for i in range(len(a)):\n",
    "    if a[i]<=20:   #setting the threshold as 20%\n",
    "        variable.append(variables[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Identifier',\n",
       " 'Item_Weight',\n",
       " 'Item_Fat_Content',\n",
       " 'Item_Visibility',\n",
       " 'Item_Type',\n",
       " 'Item_MRP',\n",
       " 'Outlet_Identifier',\n",
       " 'Outlet_Establishment_Year',\n",
       " 'Outlet_Location_Type',\n",
       " 'Outlet_Type',\n",
       " 'Item_Outlet_Sales']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the variables to be used are stored in “variable”, which contains only those features where the missing values are less than 20%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Variance Filter\n",
    "Consider a variable in our dataset where all the observations have the same value, say 1. If we use this variable, do you think it can improve the model we will build? The answer is no, because this variable will have zero variance.\n",
    "\n",
    "So, we need to calculate the variance of each variable we are given. Then drop the variables having low variance as compared to other variables in our dataset. The reason for doing this, as I mentioned above, is that variables with a low variance will not affect the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first impute the missing values in the Item_Weight column using the median value of the known Item_Weight observations. For the Outlet_Size column, we will use the mode of the known Outlet_Size values to impute the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Weight'].fillna(train['Item_Weight'].median(), inplace=True)\n",
    "train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check whether all the missing values have been filled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier              0.0\n",
       "Item_Weight                  0.0\n",
       "Item_Fat_Content             0.0\n",
       "Item_Visibility              0.0\n",
       "Item_Type                    0.0\n",
       "Item_MRP                     0.0\n",
       "Outlet_Identifier            0.0\n",
       "Outlet_Establishment_Year    0.0\n",
       "Outlet_Size                  0.0\n",
       "Outlet_Location_Type         0.0\n",
       "Outlet_Type                  0.0\n",
       "Item_Outlet_Sales            0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set. Now let’s calculate the variance of all the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight                  1.786956e+01\n",
       "Item_Visibility              2.662335e-03\n",
       "Item_MRP                     3.878184e+03\n",
       "Outlet_Establishment_Year    7.008637e+01\n",
       "Item_Outlet_Sales            2.912141e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above output shows, the variance of Item_Visibility is very less as compared to the other variables. We can safely drop this column. This is how we apply low variance filter. Let’s implement this in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = train[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]\n",
    "var = numeric.var()\n",
    "numeric = numeric.columns\n",
    "variable = [ ]\n",
    "for i in range(0,len(var)):\n",
    "    if var[i]>=10:   #setting the threshold as 10%\n",
    "        variable.append(numeric[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code gives us the list of variables that have a variance greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Weight', 'Item_MRP', 'Outlet_Establishment_Year'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable\n",
    "X= train[['Item_Weight', 'Item_MRP', 'Outlet_Establishment_Year']]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Correlation filter\n",
    "High correlation between two variables means they have similar trends and are likely to carry similar information. This can bring down the performance of some models drastically (linear and logistic regression models, for instance). We can calculate the correlation between independent numerical variables that are numerical in nature. If the correlation coefficient crosses a certain threshold value, we can drop one of the variables (dropping a variable is highly subjective and should always be done keeping the domain in mind).\n",
    "\n",
    "As a general guideline, we should keep those variables which show a decent or high correlation with the target variable.\n",
    "\n",
    "Let’s perform the correlation calculation in Python. We will drop the dependent variable (Item_Outlet_Sales) first and save the remaining variables in a new dataframe (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014168</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>0.007739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>-0.014168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.074834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0.024951</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <td>0.007739</td>\n",
       "      <td>-0.074834</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Item_Weight  Item_Visibility  Item_MRP  \\\n",
       "Item_Weight                   1.000000        -0.014168  0.024951   \n",
       "Item_Visibility              -0.014168         1.000000 -0.001315   \n",
       "Item_MRP                      0.024951        -0.001315  1.000000   \n",
       "Outlet_Establishment_Year     0.007739        -0.074834  0.005020   \n",
       "\n",
       "                           Outlet_Establishment_Year  \n",
       "Item_Weight                                 0.007739  \n",
       "Item_Visibility                            -0.074834  \n",
       "Item_MRP                                    0.005020  \n",
       "Outlet_Establishment_Year                   1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=train.drop('Item_Outlet_Sales', 1)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful, we don’t have any variables with a high correlation in our dataset. Generally, if the correlation between a pair of variables is greater than 0.5-0.6, we should seriously consider dropping one of those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "Random Forest is one of the most widely used algorithms for feature selection. It comes packaged with in-built feature importance so you don’t need to program that separately. This helps us select a smaller subset of features.\n",
    "\n",
    "We need to convert the data into numeric form by applying one hot encoding, as Random Forest (Scikit-Learn Implementation) takes only numeric inputs. Let’s also drop the ID variables (Item_Identifier and Outlet_Identifier) as these are just unique numbers and hold no significant importance for us currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "df=df.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)\n",
    "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "df=pd.get_dummies(df)\n",
    "model.fit(df,train.Item_Outlet_Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, plot the feature importance graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = df.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above graph, we can hand pick the top-most features to reduce the dimensionality in our dataset. Alernatively, we can use the SelectFromModel of sklearn to do so. It selects the features based on the importance of their weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward/Backward Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)         # for dataset dimension\n",
    "print(boston.feature_names)      # for feature names\n",
    "print(boston.target)             # for target variable\n",
    "print(boston.DESCR)              # for data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s convert this raw data into a data frame including target variable and actual data along with feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bos = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "bos['Price'] = boston.target\n",
    "X = bos.drop(\"Price\", 1)       # feature matrix\n",
    "y = bos['Price']               # target feature\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Feature Selection\n",
    "In forward selection, we start with a null model and then start fitting the model with each individual feature one at a time and select the feature with the minimum p-value. Now fit a model with two features by trying combinations of the earlier selected feature with all other remaining features. Again select the feature with the minimum p-value. Now fit a model with three features by trying combinations of two previously selected features with other remaining features. Repeat this process until we have a set of selected features with a p-value of individual features less than the significance level.\n",
    "\n",
    "In short, the steps for the forward selection technique are as follows :\n",
    "\n",
    "1. Choose a significance level (e.g. SL = 0.05 with a 95% confidence).\n",
    "\n",
    "2. Fit all possible simple regression models by considering one feature at a time. Total ’n’ models are possible. Select the feature with the lowest p-value.\n",
    "\n",
    "3. Fit all possible models with one extra feature added to the previously selected feature(s).\n",
    "\n",
    "4. Again, select the feature with a minimum p-value. if p_value < significance level then go to Step 3, otherwise terminate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function accepts data, target variable, and significance level as arguments and returns the final list of significant features based on p-values through forward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodgupta/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LSTAT',\n",
       " 'RM',\n",
       " 'PTRATIO',\n",
       " 'DIS',\n",
       " 'NOX',\n",
       " 'CHAS',\n",
       " 'B',\n",
       " 'ZN',\n",
       " 'CRIM',\n",
       " 'RAD',\n",
       " 'TAX']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selection(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Feature Elimination\n",
    "Backward elimination\n",
    "In backward elimination, we start with the full model (including all the independent variables) and then remove the insignificant feature with the highest p-value(> significance level). This process repeats again and again until we have the final set of significant features.\n",
    "\n",
    "In short, the steps involved in backward elimination are as follows:\n",
    "\n",
    "1. Choose a significance level (e.g. SL = 0.05 with a 95% confidence).\n",
    "\n",
    "2. Fit a full model including all the features.\n",
    "\n",
    "3. Consider the feature with the highest p-value. If the p-value > significance level then go to Step 4, otherwise terminate the process.\n",
    "\n",
    "4. Remove the feature which is under consideration.\n",
    "\n",
    "5. Fit a model without this feature. Repeat the entire process from Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features])\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This above function returns the final list of significant features based on p-values through backward elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_elimination(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/#h2_6\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/?#\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
